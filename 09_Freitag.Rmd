# Weitere Hypothesentests {#hypo}

```{r setup9, include=F}
.libPaths("D:/R-library4") 
library(tidyverse)
library(ggplot2)
library(LaCroixColoR)
library(patchwork)
library(Statamarkdown)
stataexe <- "C:/Program Files (x86)/Stata13/StataSE-64.exe"
knitr::opts_chunk$set(engine.path=list(stata=stataexe))
knitr::opts_chunk$set(collapse = F)

ak <- readr::read_delim("D:/oCloud/RFS/allbus_kumuliert_1980-2018.csv", delim = ";", col_types = cols(.default = col_double())) 
a14gr <- filter(ak, year == 2014, hs16>0 )
```

## Vergleich von Varianzen mit dem F-Test

Um die Varianzen zweier Stichproben zu überprüfen, steht uns der F-Test zur Verfügung - in Stata mit `sdtest`. Der F-Test hat einige Voraussetzungen: 

+	Die Variablen sind (mind.) intervallskaliert 
+	Die Variablen sind in der Grundgesamtheit (annähernd) normalverteilt
+	Die zu vergleichenden Gruppen sind voneinander unabhängig (unverbundene Stichproben)

Getestet wird beim F-Test die Hypothese, dass die Varianzen zweier Grundgesamtheiten gleich oder ungleich (zweiseitiger Test) sind bzw. dass die Varianz der einen Grundgesamtheit größer ist als die der anderen (einseitiger Test).

Es gibt also auch hier wieder gerichtete und ungerichtete Hypothesen. Da allerdings die F-Verteilung nicht symmetrisch ist, wird nur rechtsseitig getestet. Daher sollte beim Test die größere Varianz immer im Zähler stehen.

  + ungerichtete/beidseitige Hypothese:  
  
  $\qquad H_0: \frac{\sigma^{2}_{1}}{\sigma^{2}_{2}} = 1 \qquad H_A: \frac{\sigma^{2}_{1}}{\sigma^{2}_{2}} \neq 1 \qquad \qquad \Rightarrow H_A:\;\sigma^{2}_{1} \neq \sigma^{2}_{2}$  
  
  + rechtsseitige Hypothese: 
  
  $\qquad H_0: \frac{\sigma^{2}_{1}}{\sigma^{2}_{2}} \leqslant 1 \qquad H_A: \frac{\sigma^{2}_{1}}{\sigma^{2}_{2}} > 1 \qquad \qquad \Rightarrow H_A:\;\sigma^{2}_{1}>\sigma^{2}_{2}$  

Wie schon beim t-Test geht es bei den Hypothesen um die Grundgesamtheit. Daher wird hier der griechische Buchstabe für die Varianz, $\sigma^2$, verwendet. Da wir i.d.R. keine Angabe zur Varianz der Grundgesamtheiten vorliegen haben, wird beim F-Test auf die Stichprobenvarianzen ($s^2$) zurückgegriffen. Der Quotient der Varianzen ist F-verteilt. Somit berechnet sich die F-Statistik aus dem Quotienten der beiden Stichprobenvarianzen, wobei – nochmal – die größere Varianz im Zähler steht:
$$F = \frac{s^{2}_{1}}{s^{2}_{2}}$$
Wir kommen nochmal auf das Beispiel der Körpergrößen aus dem Allbus 2014 aus Session 8 zurück:

```{stata readin8, eval = F}
cd "..."
use  "Allbus_1980-2018.dta",clear
keep  if year == 2014 & hs16 > 0
```

Im konkreten Fall ist also $s^{2}_{Maenner}$ der Schätzer für $\sigma^{2}_{Manner}$  und  $s^{2}_{Frauen}$  der Schätzer für die $\sigma^{2}_{Frauen}$. Wir berechnen also zunächst die Stichprobenvarianzen:

```{stata ftest1, eval = F}
tabstat hs16, by(sex)
```

```{stata ftest2, echo = F}
qui cd "D:\Studium\01_Oldenburg\Lehre\Datensaetze"
qui use  "Allbus_1980-2018.dta",clear
qui keep  if year == 2014 & hs16>0
tabstat hs16, by(sex)
```


In `sdtest()` geben wir zunächst die zu testende Variable an, dann die Gruppierungsvariable:
```{stata ftest3, eval = F}
sdtest hs16, by(sex)
```
```{stata ftest4, echo = F}
qui cd "D:\Studium\01_Oldenburg\Lehre\Datensaetze"
qui use  "Allbus_1980-2018.dta",clear
qui keep  if year == 2014 & hs16>0
sdtest hs16, by(sex)
```
Da der p-Wert für den beidseitigen Test (mittlere Spalte, unter `Ha: ratio != 1`) deutlich unter 0,05 liegt wird die $H_0$ verworfen und wir gehen von ungleichen Varianzen bei den Körpergrößen von Männern und Frauen aus.  

Außerdem kann die $H_0: \frac{\sigma^{2}_{1}}{\sigma^{2}_{2}} \leqslant 1$ verworfen werden (letzte Spalte, unter `Ha: ratio > 1`). D.h. die Varianz der Körpergröße von Männern ist signifikant größer als die Varianz der Körpergröße bei Frauen.

 
## Proportionen und Häufigkeiten

### Binomialtest

Für dichtome abhängige Variablen eignet sich der Binomialtest. Wir können mit dem Binomialtest testen, ob ein Anteil eines Merkmals sich signifikant von einem Wert unterscheidet. Dieser Anteil wird als $\pi$ bezeichnet und beschreibt Auftrittswahrscheinlichkeit des interessierenden Merkmals in der Grundgesamtheit. In R können wir den Binomialtest mit `binom.test` aufrufen.
Auch hier gibt es wieder gerichtete und ungerichtete Hypothesen:  

  + ungerichtete/beidseitige Hypothese: 
  
  $H_0: \pi = p \qquad H_A: \pi \neq p$  
  
  + linksseitige Hypothese:  
  
  $H_0: \pi \geqslant p \qquad H_A: \pi < p$  
  
  + rechtssseitige Hypothese:   
  $H_0: \pi \leqslant p \qquad H_A: \pi > p$  


Wir könnten uns zB. fragen ob der Anteil der Befragten ohne Haustier im Allbus 2014 sich von $67\%$ unterscheidet. Dazu wählen wir zunächst alle Befragten des Allbus 2014 aus, welche die Frage nach den Haustieren (`aq03`) beantwortet haben (`aq < 0` sind missings, daher verwenden wir schlicht `aq03 > 0`). Dazu erstellen wir aus `aq03` noch eine Dummyvariable, welche 1 für das interessierende Merkmal (kein Haustierbesitz) und 0 in allen anderen Fällen annimmt:
```{stata, eval = F}
cd ""
use  "Allbus_1980-2018.dta",clear
keep  if year == 2014 & aq03>0
gen pet = (aq03 == 4)
tab aq03 pet
```

```{stata, echo = F}
qui cd "D:\Studium\01_Oldenburg\Lehre\Datensaetze"
qui use  "Allbus_1980-2018.dta",clear
qui keep  if year == 2014 & aq03>0
gen pet = (aq03 == 4)
tab aq03 pet
```

Mit ` bitest` können wir dann den Binomialtest durchführen, dieser test immer auf :
```{stata btest1, eval = F}
bitest pet == .67
```


```{stata btest2, echo = F}
qui cd "D:\Studium\01_Oldenburg\Lehre\Datensaetze"
qui use  "Allbus_1980-2018.dta",clear
qui keep  if year == 2014 & aq03>0
qui gen pet = (aq03 == 4)
bitest pet == .67
```
Der rechtsseitige Test (erste Zeile) ergibt, dass der Anteil der Befragten ohne Haustier signifikant größer als 67% ist.
Der linksseitige Test (zweite Zeile) ergibt, dass der Anteil der Befragten ohne Haustier nicht signifikant kleiner als 67% ist.
Außerdem können wir auf Basis des beidseitigen Tests (letzte Zeile) die $H_0: \pi = .67$ nicht verwerfen, da der p-Wert größer 0,05 ist. Der Anteil der Befragten ohne Haustier unterscheidet sich also nicht signifikant von 67\%.


### Chi²-Test

Häufig ist aber auch für dichtome Merkmale von Interesse, ob sich die Auftrittswahrscheinlichkeit zwischen zwei Gruppen unterscheidet. Hierfür eignet sich der $\chi^{2}$-Test. Der $\chi^{2}$-Test testet, ob sich die beobachteten absoluten Häufigkeiten signifikant von den absoluten Häufigkeiten unterscheiden, die wir erwarten würden wenn beide Merkmale unabhängig voneinander sind. Die Differenz zwischen der beobachteten und der erwarteten absoluten Häufigkeit ergibt den $\chi^{2}$-Wert. Ist $\chi^{2} \approx 0$, dann können wir davon ausgehen, dass die beiden Merkmale unabhängig voneinander sind. Ist $\chi^{2}$ aber größer Null, so gehen wir von einem Zusammenhang aus. Beim $\chi^{2}$-Test geht die $H_0$ davon aus, dass es keinen Zusammenhang gibt. Die $H_{A}$ besagt hingegen, dass einen Zusammenhang zwischen den beiden untersuchten Merkmalen besteht.

$H_{0}: \chi^2 = 0 \qquad H_A: \chi^2 > 0$

Den $\chi^2$-Test erhalten wir, indem wir mit `tabulate` eine Kontingenztabelle erstellen und die Option `chi` angeben. Beispielsweise könnten wir untersuchen, ob es einen Zusammenhang zwischen dem Geschlecht der Befragten und dem Haustierbesitz gibt:


```{stata chi_test2, eval = F}
tab sex pet, chi
```

```{stata chi_test3, echo = F}
qui cd "D:\Studium\01_Oldenburg\Lehre\Datensaetze"
qui use  "Allbus_1980-2018.dta",clear
qui keep  if year == 2014 & aq03>0
qui gen pet = (aq03 == 4)
tab aq03 pet, chi
```


Da der p-Wert deutlich unter 0,05 liegt, können wir davon ausgehen, dass es in der Grundgesamtheit einen Zusammenhang zwischen dem Geschlecht der Befragten und dem Haustierbesitz gibt.


## Überblick

In allen Tests (außer $\chi^2$) können beidseitige, linksseitige oder rechtsseitige Hypothesen untersucht werden. 

+ Mittelwertvergleich: `ttest`
  + Vergleich zu einem Referenzwert: `ttest testvariable == referenzwert`

  Zudem gibt es bein Mittelwertvergleichen insgesamt zwei Aspekte, anhand derer sich t-Tests allgemein unterscheiden:

  + Die Varianz der Messwerte in den verglichenen Gruppen ist ...
    + gleich: $\Rightarrow$ `ttest testvariable, by(gruppenvariable)` 
    + verschieden: $\Rightarrow$ `ttest testvariable, by(gruppenvariable) unequal` 
    
  + Verbundene oder unverbundene Stichprobe?
    +  Sind die einzelnen Messwerte voneinander unabhängig? D.h. ein Messwert steht in keinem direkten Zusammenhang mit einem anderen $\Rightarrow$ `ttest testvariable, by(gruppenvariable)` für eine unverbundene Stichprobe (mit ggf. `unequal`)
    +  Stehen die einzelnen Messwerte in einem Zusammenhang? D.h. ein Messwert steht in einem direkten Zusammenhang mit einem anderen $\Rightarrow$ Werte für beide Variablen sollten "nebeneinander" abgelegt sein (*wide*-Format), dann kann mit `ttest vorher==nachher` ein verbundener `ttest` durchgeführt werden.

+ Varianzvergleich,unterscheidet sich die Varianz zwischen zwei Gruppen?
  + `sdtest testvariable, by(gruppenvariable)`


+ Anteile vergleichen:
  + mit einem behaupteten Wert: `bitest testvariable == referenzwert`  
  
  + zwischen Gruppen: Kreuztabelle erstellen und mit `tab var1 var2, chi` Unabhängigkeit testen
