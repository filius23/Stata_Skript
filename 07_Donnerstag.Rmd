# Inferenzstatistik I {#inf1}

```{r setup7, echo = F, message=F, warning = F}
.libPaths("D:/R-library4")
library(Statamarkdown)
library(tidyverse)
library(ggrepel)
stataexe <- "C:/Program Files (x86)/Stata13/StataSE-64.exe"
knitr::opts_chunk$set(engine.path=list(stata=stataexe))
knitr::opts_chunk$set(collapse = F)
ak <- readr::read_delim("D:/oCloud/RFS/allbus_kumuliert_1980-2018.csv", delim = ";", col_types = cols(.default = col_double())) %>% 
  mutate_all( ~ifelse(.<0,NA,.))
a14m <- filter(ak,year == 2014, sex == 1, !is.na(hs16) )  
```

Wir möchten auf Basis des Allbus von 2014 die durchschnittliche Körpergröße von Männern in Deutschland ermitteln. Dazu lesen wir zunächst den Datensatz ein und wählen dann nur die Angaben für das Jahr 2014 aus, die zugleich auch von Männern (`sex == 1`) sind. Um bei der weiteren Berechnung die Missings ignorieren zu können, filtern wir mit `hs16 > 0` zusätzlich nur nach den Beobachtungen nicht eine gültige Angabe für `hs16` haben:

```{stata readin7, eval = F}
cd ""
use  "Allbus_1980-2018.dta",clear
keep if year == 2014 & sex ==  1 & hs16 > 0
```

```{stata readin7b, echo= F}
qui cd "D:\Studium\01_Oldenburg\Lehre\Datensaetze"
qui use  "Allbus_1980-2018.dta",clear
keep if year == 2014 & sex ==  1 & hs16 > 0
```


## Inferenz

Wenn wir jetzt die durchschnittliche Körpergröße berechnen, ist das zwar für die Stichprobe korrekt (und exakt):
```{stata mean1, eval = F}
tabstat hs16 , s(mean)
```

```{stata mean2, echo = F}
qui cd "D:\Studium\01_Oldenburg\Lehre\Datensaetze"
qui use  "Allbus_1980-2018.dta",clear
qui keep if year == 2014 & sex ==  1 & hs16 > 0
tabstat hs16 , s(mean)
```


Allerdings ist sehr unwahrscheinlich, dass die durchschnittliche Körpergröße in Deutschland im Jahr 2014 genau  178.7179 cm betrug. Jedoch kann auf Basis des zentralen Grenzwertsatzes angenommen werden, dass bei genügend großer Fallzahl die Mittelwerte bei wiederholten SP normalverteilt sind.

Somit können wir auf Basis einer Stichprobe das Konfidenzintervall einer Schätzung bestimmen, indem wir um den Punktschätzer (den Stichproben-Mittelwert, also die 178.7179 cm) mit Hilfe des eines geeigneten $t$-Werts und des Standardfehlers ($\frac{s}{\sqrt{n}}$[^11]) einen Wertebereich um den Mittelwert $\bar{x}$ konstruieren.

[^11]: Also die Standardabweichung ($s$) dividiert durch die Wurzel der Stichprobengröße ($n$)

$$\bar{x}\,\pm\,t\times\frac{s}{\sqrt{n}}$$

## Parametrische KI-Schätzung
### t-/z-Wert

Das $t$ kommt dabei aus der Student-t-Verteilung bzw. als $z$-Wert aus der Standard-Normalverteilung. $t$ wählen wir dabei so, dass bei wiederholter Stichprobenziehung 95% der resultierenden KI den wahren Wert aus der Grundgesamtheit beinhalten würden:

```{r, out.height="90%", out.width="90%", fig.align='center', echo=F}
data1 <- data.frame(z = seq(-4,4,.01)) ## dataframe erstellen mit Zahlenfolge zwischen -4 & 4
data1$t.var <- dt(x=data1$z,df =  9999) 


ggplot(data = data1, aes(x=z, y =t.var)) + 
  theme_minimal(base_size = 15) +
  labs(y = "Häufigkeitsdichte", x = "t") +
  geom_ribbon(data=filter(data1,z <= - 1.960201), aes(ymin=0, ymax = t.var), fill = "#F5CC71") + ## fläche links
  geom_segment(data = data.frame(z = - 1.960201,y1 = dt(x=- 1.960201,df =  1757)) , 
            aes(x=z,y=y1,xend = z, yend = 0), color = "#404040", size = .5, linetype = 2) + ## grenze links
  geom_ribbon(data=filter(data1,z >=  1.960201), aes(ymin=0, ymax = t.var), fill = "#F5CC71") + ## fläche rechts
  geom_segment(data = data.frame(z =  1.960201,y1 = dt(x= 1.960201,df =  1757)) , 
            aes(x=z,y=y1,xend = z, yend = 0), color = "#404040", size = .5, linetype = 2) + ## grenze rechts
  geom_segment(data = data.frame(z = 0,y1 = dt(x=0,df = 9999)) , 
            aes(x=z,y=y1,xend = z, yend = 0), color = "grey50", size = .5, linetype = 3) + ## mittellinie
  geom_segment(data = data.frame(z = 0,y1 = dt(x=0,df = 9999)) , 
            aes(x=z,y=-0.0125,xend = -1.85, yend = -0.0125), color = "grey25", size = .5,
            arrow = arrow(length = unit(0.5, "lines"), type = "closed")) + ## pfeil nach links
  geom_segment(data = data.frame(z = 0,y1 = dt(x=0,df = 9999)) , 
            aes(x=z,y=-0.0125,xend = 1.85, yend = -0.0125), color = "grey25", size = .5,
            arrow = arrow(length = unit(0.5, "lines"), type = "closed")) + #pfeil nach rechts
  geom_label(data=data.frame(z = 0 , y1 = -0.0125, lab1 = "+/- 1.96", t.var = 0),aes(label = lab1), size = 3.5 ) +
  geom_line(color = "navy")  +   
  scale_x_continuous(breaks = seq(-3,3,1),minor_breaks = seq(-3,3,1))+
  theme(aspect.ratio = 1, panel.grid = element_line(size = rel(.25))) +
  geom_text(data=data.frame(z = c(-3,3), t.var = 0.015, label = rep(paste0(round(pt(q = -1.959964,df = 9999)*100,2),"%"),2) ), 
                            aes(x = z, y = t.var, label = label),
                            size = 3.25,vjust= 0, hjust = c(1,0))
```
Aufgrund der Symmetrie teilen wir die Irrtumswahrscheinlichkeit also auf jeweils 2,5% auf und können mit `invttail(df,p)` den entsprechenden $t$-Wert nachsehen, wobei `df` = $n-1$ und p die Irrtumswahrscheinlichkeit bezeichnet. `invttail` kumuliert dabei von *rechts nach links*. Die gezeigte Verteilung unterstellt dabei eine Stichprobe von $n=10.000$:

+ bei welchem t-Wert liegen 2.5% *rechts* davon?
```{stata invttail1}
display invttail(9999,0.025) 
```
+ bei welchem t-Wert liegen 2.5% *links* bzw. 97.5% rechts davon?
```{stata invttail2}
display invttail(9999,0.975) 
```

Für kleine Stichproben ist der t-Wert deutlich größer, um die zusätzliche Unsicherheit der Stichprobengröße zu berücksichtigen. Mit steigendem $n$ bzw. $df$ nähert sich der t-Wert dem z-Wert der Standard-NV an:

```{stata invttail3}
display invnormal(.025) // z-Wert aus Standard-NV
```
```{stata invttail31}
display invttail(3,   .975)
```
```{stata invttail32}
display invttail(30,  .975)
```
```{stata invttail33}
display invttail(300, .975)
```
```{stata invttail34}
display invttail(3000,.975)
```

Leider funktioniert `invnormal` umgekehrt von `invttail` und kumuliert von links nach rechts - wie man es erwarten würde....) `invnormal` zeigt also die Fläche *links*, `invttail` die Fläche *rechts* - daher entsprechen sich `invnormal(.025)` und `invttail(df,   .975)`

Es gibt auch andere Varianten, zB. 90% oder 99%:
```{stata invttail4}
display invttail(9999,   .05)
display invttail(9999,  .005)
```



```{r,  out.width = "90%",out.height= "90%", fig.align='center', echo=F}
ki90 <- ggplot(data = data1, aes(x=z, y =t.var)) + 
  theme_minimal() +
  labs(y = "Häufigkeitsdichte", x = "t",title ="90% Konfidenzintervall") +
  geom_ribbon(data=filter(data1,z <= qt(p = .05, df = 9999)), aes(ymin=0, ymax = t.var), fill = "#FCE8CE") + ## fläche links
  geom_segment(data = data.frame(z = qt(p = .05, df = 9999),y1 = dt(x=- qt(p = .05, df = 9999),df =  1757)) , 
               aes(x=z,y=y1,xend = z, yend = 0), color = "#404040", size = .5, linetype = 2) + ## grenze links
  geom_ribbon(data=filter(data1,z >=  qt(p = .95, df = 9999)), aes(ymin=0, ymax = t.var), fill = "#FCE8CE") + ## fläche rechts
  geom_segment(data = data.frame(z =  qt(p = .95, df = 9999),y1 = dt(x= qt(p = .05, df = 9999),df =  1757)) , 
               aes(x=z,y=y1,xend = z, yend = 0), color = "#404040", size = .5, linetype = 2) + ## grenze rechts
  geom_segment(data = data.frame(z = 0,y1 = dt(x=0,df = 9999)) , 
               aes(x=z,y=y1,xend = z, yend = 0), color = "grey50", size = .5, linetype = 3) + ## mittellinie
  geom_segment(data = data.frame(z = 0,y1 = dt(x=0,df = 9999)) , 
               aes(x=z,y=-0.0125,xend = -1.64, yend = -0.0125), color = "grey25", size = .5,
               arrow = arrow(length = unit(0.5, "lines"), type = "closed")) + ## pfeil nach links
  geom_segment(data = data.frame(z = 0,y1 = dt(x=0,df = 9999)) , 
               aes(x=z,y=-0.0125,xend = 1.64, yend = -0.0125), color = "grey25", size = .5,
               arrow = arrow(length = unit(0.5, "lines"), type = "closed")) + #pfeil nach rechts
  geom_label(data=data.frame(z = 0 , y1 = -0.0125, lab1 = paste0("+/- ",round(qt(p = .95, df = 9999),3)), t.var = 0),aes(label = lab1), size = 2.75 ) +
  geom_line(color = "#263056")  +   
  scale_x_continuous(breaks = seq(-3,3,1),minor_breaks = seq(-3,3,1))+
  theme(aspect.ratio = 1, panel.grid = element_line(size = rel(.25))) +
  geom_text(data=data.frame(z = c(-3,3), t.var = 0.015, label = rep(paste0(round(pt(q = -1.645,df = 9999)*100,3),"%"),2) ), 
            aes(x = z, y = t.var, label = label),
            size = 3.25,vjust= 0, hjust = c(1,0))+
  theme(plot.margin = margin(0, 0.1, 0, 0.1, "cm"), plot.title = element_text(hjust = .5))

ki99 <- ggplot(data = data1, aes(x=z, y =t.var)) + 
  theme_minimal() +
  labs(y = "Häufigkeitsdichte", x = "t",title ="99% Konfidenzintervall") +
  geom_ribbon(data=filter(data1,z <= qt(p = .005, df = 9999)), aes(ymin=0, ymax = t.var), fill = "#FFABC2") + ## fläche links
  geom_segment(data = data.frame(z = qt(p = .005, df = 9999),y1 = dt(x=- qt(p = .005, df = 9999),df =  1757)) , 
               aes(x=z,y=y1,xend = z, yend = 0), color = "#404040", size = .5, linetype = 2) + ## grenze links
  geom_ribbon(data=filter(data1,z >=  qt(p = .995, df = 9999)), aes(ymin=0, ymax = t.var), fill = "#FFABC2") + ## fläche rechts
  geom_segment(data = data.frame(z =  qt(p = .995, df = 9999),y1 = dt(x= qt(p = .005, df = 9999),df =  1757)) , 
               aes(x=z,y=y1,xend = z, yend = 0), color = "#404040", size = .5, linetype = 2) + ## grenze rechts
  geom_segment(data = data.frame(z = 0,y1 = dt(x=0,df = 9999)) , 
               aes(x=z,y=y1,xend = z, yend = 0), color = "grey50", size = .5, linetype = 3) + ## mittellinie
  geom_segment(data = data.frame(z = 0,y1 = dt(x=0,df = 9999)) , 
               aes(x=z,y=-0.0125,xend = -2.55, yend = -0.0125), color = "grey25", size = .5,
               arrow = arrow(length = unit(0.5, "lines"), type = "closed")) + ## pfeil nach links
  geom_segment(data = data.frame(z = 0,y1 = dt(x=0,df = 9999)) , 
               aes(x=z,y=-0.0125,xend = 2.55, yend = -0.0125), color = "grey25", size = .5,
               arrow = arrow(length = unit(0.5, "lines"), type = "closed")) + #pfeil nach rechts
  geom_label(data=data.frame(z = 0 , y1 = -0.0125, lab1 = paste0("+/- ",round(qt(p = .995, df = 9999),3)), t.var = 0),aes(label = lab1), size = 2.75 ) +
  geom_line(color = "#263056")  +   
  scale_x_continuous(breaks = seq(-3,3,1),minor_breaks = seq(-3,3,1))+
  theme(aspect.ratio = 1, panel.grid = element_line(size = rel(.25))) +
  geom_text(data=data.frame(z = c(-3,3), t.var = 0.015, label = rep(paste0(round(pt(q = -2.576321,df = 9999)*100,3),"%"),2) ), 
            aes(x = z, y = t.var, label = label),
            size = 3.25,vjust= 0, hjust = c(1,0)) +
  theme(plot.margin = margin(0, 0.1, 0, 0.1, "cm"), plot.title = element_text(hjust = .5))
library(patchwork)
ki90 + ki99
```



### Standardfehler

Der zweite Bestandteil der Formel $\frac{s}{\sqrt{n}}$  ergibt sich aus den Stichprobenparametern: $s$ ist die Standardabweichung in der Stichprobe und $n$ ist die Stichprobengröße. Um diese nachzusehen, können wir mit `tabstat hs16, s(sd n)` die Standardabweichung sowie die Fallzahl (ohne Missings) ausgeben lassen. Da wir `mean` auch gleich benötigen, lassen wir uns das auch nochmal ausgeben:
```{stata n, eval = F}
tabstat hs16, s(mean sd n)
```

```{stata n2, echo = F}
qui cd "D:\Studium\01_Oldenburg\Lehre\Datensaetze"
qui use  "Allbus_1980-2018.dta",clear
qui keep if year == 2014 & sex ==  1 & hs16 > 0
tabstat hs16, s(mean sd n)
```

```{stata t_val}
display invttail( 1758-1,  .025)
```

### KIs berechnen
Dann können wir für unsere Körpergrößenschätzung folgendes 95%-KI berechnen - zur Erinnerung die Formel:

$$\bar{x}\,\pm\,t\times\frac{s}{\sqrt{n}}$$

Untere 95%Grenze:
```{stata ki_manual}
dis 178.7179 - 1.9613151* 7.18002 / sqrt(1758)
```
Obere 95%-Grenze:
```{stata ki_manual2}
dis 178.7179 + 1.9613151* 7.18002 / sqrt(1758)
```

Für das 90%-KI würde sich entsprechend ergeben:
```{stata invttail90}
display invttail( 1758-1,  .05)
```

Untere 90%-Grenze:
```{stata ki_manual90}
dis 178.7179 - 1.6457213* 7.18002 / sqrt(1758)
```
Obere 90%-Grenze:
```{stata ki_manual902}
dis 178.7179 + 1.6457213* 7.18002 / sqrt(1758)
```

### `mean`
Die gute Nachricht: Stata macht das mit `mean` automatisch für uns:
```{stata mean, eval = F}
mean hs16 // Standard ist 95%
```
```{stata mean2x, echo = F}
qui cd "D:\Studium\01_Oldenburg\Lehre\Datensaetze"
qui use  "Allbus_1980-2018.dta",clear
qui keep if year == 2012 & sex ==  1 & hs16 > 0
mean hs16 // Standard ist 95%
```

```{stata mean3, eval = F}
mean hs16,level(90) // mit level(90) kann das 90%-KI angefordert werden
```
```{stata mean4, echo = F}
qui cd "D:\Studium\01_Oldenburg\Lehre\Datensaetze"
qui use  "Allbus_1980-2018.dta",clear
qui keep if year == 2012 & sex ==  1 & hs16 > 0
mean hs16,level(90) 
```

### Vergleich 
```{r, echo = F,out.width = "70%",fig.height=2, fig.align='center', warning=F, message=F}
dfx <- data.frame(
    type = factor(c("99% KI", "95% KI", "90% KI"), levels = c("99% KI", "95% KI", "90% KI")),
    m = rep(mean(a14m$hs16),3),
    cil = c(
      mean(a14m$hs16) - qt(p=.995,df = nrow(a14m)-1)*sd(a14m$hs16)/sqrt(nrow(a14m)),
      mean(a14m$hs16) - qt(p=.975,df = nrow(a14m)-1)*sd(a14m$hs16)/sqrt(nrow(a14m)),
      mean(a14m$hs16) - qt(p=.95, df = nrow(a14m)-1)*sd(a14m$hs16)/sqrt(nrow(a14m))),
    ciu = c(
      mean(a14m$hs16) + qt(p=.995,df = nrow(a14m)-1)*sd(a14m$hs16)/sqrt(nrow(a14m)),
      mean(a14m$hs16) + qt(p=.975,df = nrow(a14m)-1)*sd(a14m$hs16)/sqrt(nrow(a14m)),
      mean(a14m$hs16) + qt(p=.95, df = nrow(a14m)-1)*sd(a14m$hs16)/sqrt(nrow(a14m)))
    ) 
ggplot(data =dfx , aes(x = type, y =m )) +
  geom_errorbar(aes( ymin = cil, ymax = ciu), width  = .45, size  = .5,
       fill = "#1f1f4f", color = "#1f1f4f") +
  geom_point(size = 3, shape = 21,
       fill = "#8f8fa7",color = "#1f1f4f") + 
  coord_flip() +
  theme_minimal(base_size = 11) +
  theme(
        panel.grid.minor.y = element_blank(),
        panel.grid.minor.x = element_blank(),
        axis.title.y = element_blank(),
        axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        ## panel.border = element_rect(color = "grey25"),
        plot.background = element_rect(color = NA),
        aspect.ratio = .15) +
  labs(y= "Körpergröße (in cm)") +
  ylim(177.5,180) + 
  theme(plot.margin = margin(0, 0.1, 0, 0.1, "cm"))
```

***

[Übung1](#KI_param)

***

## Bootstrapping

Bootstrapping ([mehr zB hier](https://statisticsbyjim.com/hypothesis-testing/bootstrapping/)) beruht auf der Idee, wiederholt Stichproben *B* aus der Stichprobe zu ziehen und aus dieser *B* die Parameter zu berechnen. Für das Bootstrapping ziehen wir wiederholt SP *mit Zurücklegen* der gleichen Größe wie die Ausgangs-SP, also hier n = `r length(a14m$hs16)` und berechnen anschließend das arith. Mittel $\bar{x}_{1}^{*}$ für diese simulierte Stichprobe. Diesen Vorgang wiederholen wir b Male und berechnen für die so gesammelten Mittelwerte $\bar{x}_{b}^{*}$ aus den simulierten Stichproben die Standardabweichung. Analog zur vorhin gezeigten parametrischen Methode können wir das KI dann als $mean(\bar{x}^{*})\,\pm t * sd(\bar{x}^{*})$ berechnen:

```{r boot_illustration, echo = F,out.width = "90%",fig.align='center', warning=F, message=F}
library(scico)
set.seed(90459000)
df1 <- tibble(x = runif(10,1,25)) %>% 
  arrange(x) %>% 
  mutate(id=1:10)
boot_df <- 
  df1 %>% 
  select(-x) %>% 
  mutate(id0 = id,
         id1 = sample(id,10,replace = T),
         id2 = sample(id,10,replace = T),
         id3 = sample(id,10,replace = T),
         id4 = sample(id,10,replace = T),
         id5 = sample(id,10,replace = T)) %>% 
  relocate(id) %>% 
  pivot_longer(cols = matches("id\\d"), names_prefix = "id", names_to = "iter", values_to = "sampl1" ) %>% 
  group_by(iter) %>% 
  left_join(df1, by = c("sampl1" = "id")) %>% 
  mutate(rang = rank(sampl1,ties.method = "random"),
         sampl1 = factor(sampl1,levels = 1:10),
         meanx = mean(x)) %>% 
  arrange(iter,id) %>% 
  ungroup() %>% 
  mutate(iter = ifelse(iter==0,-1,iter) %>% as.numeric(.))

eq1 <-  substitute(italic(bar(x)~"=")) # formel erstellen
eq2 <-  substitute(italic(bar(x)^"*"~"=")) # formel erstellen *

ggplot(boot_df) +
    aes(x= iter, y = rang, fill = sampl1, label = round(x,1) ) +
    geom_tile(color = "white", size = 3)  +
    geom_text(hjust = 0.5, size = 7, family = "serif", color = "white") +
    geom_text(data = filter(boot_df,rang == 1),
              aes(y = 0,label = round(meanx,1)),
              hjust = 0.5, size = 6.5, family = "serif", color = "black") +
    geom_text(data = data.frame(iter = -2, sampl1 = "1"),
              aes(y = -.05,label = as.character(as.expression(eq1))),
              hjust = 0.5, size = 7, family = "serif", color = "black", parse = T) + # \bar(x)
    geom_text(data = data.frame(iter = 0, sampl1 = "1"),
              aes(y = 0.075,label = as.character(as.expression(eq2))),
              hjust = 0.5, size = 7, family = "serif", color = "black", parse = T) + # \bar(x)*
    scale_fill_scico_d(palette = "lapaz",end = .85) +
    scale_x_continuous(position = "top", breaks = c(-1,1:5), labels = c("orig",1:5) ) +
    labs(x = "Iteration B =", title = "Bootstrapping mit 5 Iterationen (reps)") +
    theme_minimal() +
    guides(fill = FALSE) +
    theme(plot.title =   element_text(hjust = 0.5, size = 19), 
          axis.title.x.top = element_text(hjust = 0.5, size = 17, vjust = 1),
          axis.text.x.top = element_text(hjust = 0.5, size = 15, vjust = 0 ),
          panel.grid = element_blank(), 
          axis.title.y = element_blank(), 
          axis.text.y = element_blank(),
          aspect.ratio = .8)
```


In Stata ist dieser Prozess sehr einfach mit dem Befehl `bootstrap` zu erledigen. Wir geben dabei an, welche Kennzahl wir berechnen möchten (`r(mean)` für das arith. Mittel) und mit `reps` die Anzahl der Wiederholungen. Mit `summarize hs16` legen wir zudem fest, welchen Befehl Stata auf die wiederholten Stichproben anwenden soll - bootstrapping ist für eine ganze Reihe an Funktionen verfügbar. Hier möchten wir ja aber das arith. Mittel, demensprechend geben wir hier `summarize` mit den gewünschten Variable an.

Da es sich hier um einen Zufallsprozess handelt, wird das Ergebnis von Mal zu Mal schwanken - für Demonstrationszwecke setze ich hier mit `set seed` die Zufallsauswahl fix, um ein reproduzierbares Ergebnis zu erhalten. 

```{stata boot1, eval = F}
set seed 1212
bootstrap r(mean), reps(2000): summarize hs16
```

```{stata boot1R, echo = F}
set linesize 200
qui use  "D:/oCloud/Home-Cloud/Lehre/Methodenseminar/Allbus_1980-2018.dta"
qui keep if year == 2014 & sex ==  1 & hs16 > 0
set seed 1212
bootstrap r(mean), reps(2000): summarize hs16
```

Auf diese Weise erhalten wir ein 95% Konfidenzintervall  von 178.3822 - 179.0536. Zum Vergleich, die parametrische Methode auf Basis der t-Verteilung ergab  177.7317 - 178.7054. 

Auch hier können wir mit `level(90)` das 90%-KI berechnen lassen. Mit `nodots` können wir den Output etwas übersichtlicher machen:
```{stata boot2, eval = F}
set seed 1212
bootstrap r(mean),nodots reps(100): summarize hs16,  level(90)      
```
```{stata boot2R, echo = F}
set linesize 200
qui use  "D:/oCloud/Home-Cloud/Lehre/Methodenseminar/Allbus_1980-2018.dta"
qui keep if year == 2014 & sex ==  1 & hs16 > 0
set seed 1212
bootstrap r(mean),nodots reps(2000): summarize hs16, level(90) 
```

Zum Vergleich: oben mit der t-Verteilung kamen wir auf 177.8101 - 178.627.

*Anmerkung: die Warnmeldung können wir hier ignorieren. Stata warnt uns, dass hier basierend auf allen Fällen im Speicher gebootstrapped wird. Das wäre ein Problem, wenn wir nicht oben nur die hier gewünschten Beobachtungen behalten hätten. Wir hatten ja nur nicht-fehlende Angaben von Männern aus dem Jahr 2014 behalten.*

***

[Übung2](#KI_boot)

***

## Übung 7-1 {#KI_param}

(@) Berechnen Sie den Punktschätzer und das Konfidenzintervall für die Körpergröße (`hs16`) von Frauen (`sex == 2`) in Deutschland 2014!
  + Lesen Sie dazu den kumulierten Allbus (`Allbus_1980-2018.dta`) ein
  + Behalten Sie nur die nicht-fehlenden Angaben zur Körpergröße (`hs16`>0) für Frauen (`sex == 2`) aus dem Jahr 2014 im Speicher. Die Zahl der enthaltenen Zeilen entspricht der Zahl der Fälle für die weiteren Berechnungen ($n$).
  + Berechnen Sie den Punktschätzer für die durchschnittliche Körpergröße von Frauen in Deutschland 2014!
  + Berechnen Sie das 95%- Konfidenzintervall für diese Punktschätzung nach der parametrischen Methode! 
  + Wie hoch ist die untere Grenze für das Konfidenzintervall?
  + Wie hoch ist die obere Grenze für das Konfidenzintervall?
  + Wie sind die Grenzen für das 99%-KI?


## Übung 7-2 {#KI_boot}

(@) Berechnen Sie den Punktschätzer und das Konfidenzintervall für die Körpergröße (`hs16`) von Frauen (`sex == 2`) in Deutschland 2014! 
  + Berechnen Sie das Konfidenzintervall mit Hilfe des Bootstrapping-Verfahrens! Verwenden Sie `set seed 1212` für die Ergebnisse aus der Lösung.
  + Berechnen Sie auch hier das 95%- und 99%-Konfidenzintervall.


## Weitere Übungen Kap 7 

(@) Berechnen Sie den Punktschätzer und die Konfidenzintervalle für das Einkommen von in Vollzeit erwerbstätigen Frauen aus dem Jahr 2016!
  + Lesen Sie dazu den kumulierten Allbus (`Allbus_1980-2018.dta`) ein
  + Überschreiben Sie die fehlenden Werte für `inc` mit `.` 
  + Behalten Sie nur die nicht-fehlenden Angaben zum Einkommen (`inc`) für in Vollzeit erwerbstätige Männer aus dem Jahr 2016 im Speicher. Die Erwerbstätigkeit der Befragten wird in `work` erfasst, `work == 1` steht für in Vollzeit Erwerbstätige.
  + Berechnen Sie den Punktschätzer für das durchschnittliche Einkommen von in Vollzeit erwerbstätigen Männern in Deutschland 2016!
  + Berechnen Sie die 95%-Konfidenzintervalle nach der parametrischen und bootstrap Methode (Für die Ergebnisse aus der Lösung verwenden Sie `set.seed(1212)`)
    + 95% KI
    
(@) Berechnen Sie den Punktschätzer und die Konfidenzintervalle für das Einkommen von in Vollzeit erwerbstätigen Männern aus dem Jahr 2016!
  + Lesen Sie dazu den kumulierten Allbus (`Allbus_1980-2018.dta`) ein
  + Überschreiben Sie die fehlenden Werte für `inc` mit `.` 
  + Behalten Sie nur die nicht-fehlenden Angaben zum Einkommen (`inc`) für in Vollzeit erwerbstätige Männer aus dem Jahr 2016 im Speicher. Die Erwerbstätigkeit der Befragten wird in `work` erfasst, `work == 1` steht für in Vollzeit Erwerbstätige.
  + Berechnen Sie den Punktschätzer für das durchschnittliche Einkommen von in Vollzeit erwerbstätigen Männern in Deutschland 2016!
  + Berechnen Sie die 95%-Konfidenzintervalle nach der parametrischen und bootstrap Methode (Für die Ergebnisse aus der Lösung verwenden Sie `set.seed(1212)`)

    
    
## Anhang Kap7

### Normalverteilung 

Eine bedeutende statistische Verteilung in der angewandten Inferenzstatistik ist die Normalverteilung. Sie ist bestimmt durch zwei Parameter: das arithmetische Mittel ($\mu$) und die Standardabweichung ($\sigma$) und wird daher auch so dargestellt:

$$N(\mu,\sigma)$$
Die **Standardnormalverteilung** hat einen Mittelwert von 0 und eine Standardabweichung von 1:

$$N(0,1)$$

<!-- Die Dichtefunktion der Standardnormalverteilung können wir in Stata mit `dnorm` erzeugen: -->

```{r w8_1, out.height="50%", out.width="50%", fig.align='center', echo = F}
data1 <- data.frame(z = seq(-4,4,.01)) # dataframe erstellen mit Zahlenfolge zwischen -4 & 4
data1$nv.var <- dnorm(x=data1$z,mean = 0 ,sd =  1) # Dichtefunktion der Std-NV
library(ggplot2)
ggplot(data = data1, aes(x=z, y =nv.var)) + 
  geom_line(color = "midnightblue", alpha = .4, size = 1)  +   
  theme_minimal() + labs(y = "Häufigkeitsdichte")
```

Wir können gut erkennen, dass es sich um eine symmetrische Verteilung handelt. Für die Normalverteilung gilt, dass die Fläche unterhalb der Dichtefunktion (also unter der Linie) immer 1 beträgt. Für die Standardnormalverteilung werden die x-Achsenwerte auch als z-Werte bezeichnet. Wenn wir vom Mittelwert aus jeweils bestimmte z-Werte nach rechts und links (also positiv und negativ) als Grenzen für Teilflächen einziehen, ergeben sich verschiedene Standardwerte:

```{r w8_2, echo =F, warning=F,message=F,out.width="100%", fig.align="center"}
nv1 <- 
ggplot(data = data1, aes(x=z, y =nv.var)) + 
  geom_line(color = "midnightblue", alpha = .4, size = .65)  +   
  theme_minimal() +
  labs(y = "Häufigkeitsdichte", title = "Vollständige Fläche") +
  geom_segment(aes(xend = z, yend = 0), color = "#5b7ab0" ) +
  scale_x_continuous(breaks = seq(-3,3,1),minor_breaks = seq(-3,3,1))+
  geom_label(data= data.frame(z = 0, y = .2, label = "100%"),aes(x=z,y=y,label=label),direction = "y", size = 2)+
  theme(aspect.ratio = .6, text = element_text(size = 6),  plot.title = element_text(size = rel(1.25),hjust = .5) ,
        panel.grid.major = element_line(size = .1),panel.grid.minor = element_blank())
nv2 <-
ggplot(data = data1, aes(x=z, y =nv.var)) + 
  geom_line(color = "midnightblue", alpha = .4, size = .65)  +   
  theme_minimal() +
  labs(y = "Häufigkeitsdichte", title = "+/- 3 Standardabweichungen") +
  geom_segment(data=filter(data1,z > -3, z <3), aes(xend = z, yend = 0), color = "#516d9e" ) +
  geom_label(data= data.frame(z = 0, y = .2, label = "99,7%"),aes(x=z,y=y,label=label),direction = "y", size = 2) +
  scale_x_continuous(breaks = seq(-3,3,1),minor_breaks = seq(-3,3,1))+
  theme(aspect.ratio = .6, text = element_text(size = 6),  plot.title = element_text(size = rel(1.25),hjust = .5) ,
        panel.grid.major = element_line(size = .1),panel.grid.minor = element_blank())
nv3 <-
ggplot(data = data1, aes(x=z, y =nv.var)) + 
  geom_line(color = "midnightblue", alpha = .4, size = .65)  +   
  theme_minimal() +
  labs(y = "Häufigkeitsdichte", title = "+/- 2 Standardabweichungen") +
  geom_segment(data=filter(data1,z > -1.96, z <1.96), aes(xend = z, yend = 0), color = "#48618c" ) +
  geom_label(data= data.frame(z = 0, y = .2, label = "95,4%"),aes(x=z,y=y,label=label),direction = "y", size = 2) +
  scale_x_continuous(breaks = seq(-3,3,1),minor_breaks = seq(-3,3,1))+
  theme(aspect.ratio = .6, text = element_text(size = 6),  plot.title = element_text(size = rel(1.25),hjust = .5) ,
        panel.grid.major = element_line(size = .1),panel.grid.minor = element_blank())

nv4 <-
ggplot(data = data1, aes(x=z, y =nv.var)) + 
  geom_line(color = "midnightblue", alpha = .4, size = .65)  +   
  theme_minimal() +
  labs(y = "Häufigkeitsdichte", title = "+/- 1 Standardabweichung") +
  geom_segment(data=filter(data1,z > -1, z <1), aes(xend = z, yend = 0), color = "#3f557b" ) +
  geom_label(data= data.frame(z = 0, y = .2, label = "68,3%"),aes(x=z,y=y,label=label),direction = "y", size = 2) +
  scale_x_continuous(breaks = seq(-3,3,1),minor_breaks = seq(-3,3,1)) +
  theme(aspect.ratio = .6, text = element_text(size = 6),  plot.title = element_text(size = rel(1.25),hjust = .5),
        panel.grid.major = element_line(size = .1),panel.grid.minor = element_blank())
nv95 <-
ggplot(data = data1, aes(x=z, y =nv.var)) + 
  geom_line(color = "midnightblue", alpha = .4, size = .65)  +   
  theme_minimal() +
  labs(y = "Häufigkeitsdichte", title = "+/- 1,96 Standardabweichungen") +
  geom_segment(data=filter(data1,z > -1.96, z <1.96), aes(xend = z, yend = 0), color = "#7b94bf" ) +
  geom_label(data= data.frame(z = 0, y = .2, label = "95%"),aes(x=z,y=y,label=label),direction = "y", size = 2) +
  scale_x_continuous(breaks = seq(-3,3,1),minor_breaks = seq(-3,3,1))+
  theme(aspect.ratio = .6, text = element_text(size = 6),  plot.title = element_text(size = rel(1.25),hjust = .5) ,
        panel.grid.major = element_line(size = .1),panel.grid.minor = element_blank())

nv50 <- 
ggplot(data = data1, aes(x=z, y =nv.var)) + 
  geom_line(color = "midnightblue", alpha = .4, size = .65)  +   
  theme_minimal() +
  labs(y = "Häufigkeitsdichte", title = "Symmetrie") +
  geom_segment(data=filter(data1,z <0), aes(xend = z, yend = 0), color = "#0A7EA2" ) +
  geom_segment(data=filter(data1,z >0), aes(xend = z, yend = 0), color = "#FFD7AE" ) +
  geom_label(data= data.frame(z = c(-1,1) , y = c(.1,.1), label = "50%"),aes(x=z,y=y,label=label),direction = "y", size = 2) +
  scale_x_continuous(breaks = seq(-3,3,1),minor_breaks = seq(-3,3,1)) +
  theme(aspect.ratio = .6, text = element_text(size = 6),  plot.title = element_text(size = rel(1.25),hjust = .5),
        panel.grid.major = element_line(size = .1),panel.grid.minor = element_blank())
cowplot::plot_grid(nv1,nv2,nv3,nv4,nv50,nv95, nrow = 3, ncol = 2)  
```

#### Verteilungsfunktion

Die Übersetzung des z-Werts (x-Achsenabschnitts) in die Flächengröße leistet die sog. Verteilungsfunktion. Diese gibt die *kumulierte* Fläche wieder. Vergleichen Sie die beiden y-Achsen: für `z` $\rightarrow + \infty$ ("ganz rechts") nähert sich die Verteilungsfunktion 1 an:

```{r w8_3, echo =F, warning=F,message=F,out.width="100%", fig.align="center"}
# 
data1$nv_density <- dnorm(x=data1$z,mean = 0 ,sd =  1) # Dichtefunktion der Std-NV
data1$nv_cumdens <- pnorm(q=data1$z,mean = 0 ,sd =  1) # kumulierte Dichtefunktion

dens1 <- 
          ggplot(data = data1, aes(x=z, y =nv_density)) + 
            theme_minimal() +
            labs(y = "Häufigkeitsdichte", title = "Dichtefunktion", subtitle = "z = -0.674") +
            geom_ribbon(data=filter(data1,z <= -0.674), aes(ymin=0, ymax = nv_density), fill = "#aaaaaa", alpha = .35 ) +
            geom_segment(data = data.frame(z = -0.674,y1 = dnorm(x=-0.674,mean = 0 ,sd =  1)) , 
                      aes(x=z,y=y1,xend = z, yend = 0), color = "#404040", size = .5, linetype = 2) +
            geom_line(color = "navy")  +   
            scale_x_continuous(breaks = seq(-3,3,1),minor_breaks = seq(-3,3,1))+
            theme(aspect.ratio = 1,
                   panel.grid.major = element_line(size = .1),panel.grid.minor = element_blank())

breaks1 <- seq(0,1,.25)

cum1 <- 
ggplot(data = data1, aes(x=z, y =nv_cumdens)) + 
  geom_line(color = "#d4ba55")  +   
  theme_minimal() +
  labs(y = "kumulierte Häufigkeitsdichte", title = "Verteilungsfunktion", subtitle = "z = -0.674") +
  geom_segment(data = data.frame(z = -0.674,y1 = pnorm(q=-0.674,mean = 0 ,sd =  1)) , 
            aes(x=z,yend=y1,xend = z, y = 0), color = "#404040", size = 0.5, 
            arrow = arrow(length=unit(0.45,"lines"), ends = "last", type = "closed") ) +
  geom_point(data = data.frame(z =-0.674,y1 =-0.005), aes(x=z,y=y1),color = "grey25", shape = 15,size = 1.75) +
  geom_segment(data = data.frame(z = -0.674,y1 = pnorm(q=-0.674,mean = 0 ,sd =  1)) , 
            aes(x=z,yend=y1,xend = -4, y = y1), color = "#404040", size = 0.5,
            arrow = arrow(length=unit(0.45,"lines"), ends = "last", type = "closed") ) +
  scale_x_continuous(breaks = seq(-3,3,1),minor_breaks = seq(-3,3,1)) +
  scale_y_continuous(breaks = breaks1, minor_breaks = seq(0,1,.125)) +
  theme(aspect.ratio = 1,
         panel.grid.major = element_line(size = .1),panel.grid.minor = element_blank(),
        axis.text.y= element_text(face=ifelse(breaks1  == .25,"bold", "plain"),
                     color=ifelse(breaks1 == .25,"grey25", "black")
                     ,size=ifelse(breaks1 == .25, 11, 9 )
                     ))
dens1+cum1 + plot_layout(ncol = 2)
```

Wir können mit `normal`  berechnen lassen, wie groß jeweils die Fläche *links* von einem bestimmten Punkt auf der x-Achsen ist. Dazu setzen wir den z-Wert ein:
```{stata normal1}
display normal(-0.674)
```
Noch einmal zusammengefasst: 25% der Verteilung liegen links des z-Werts von -0.674. `z = -0.674` ist also die 1. Quartilsgrenze für eine Standardnormalverteilung. $\rightarrow$ 75% der Verteilung liegen rechts von `z = -0.674`.

**Warum ist das interessant?** Wir können damit für normalverteilte Merkmale und Kennzahlen (und das sind viele) Aussagen mit Blick auf eine Grundgesamtheit treffen, indem wir den interessierenden Wert *standardisieren*.

#### Standardisierung

Ein klassisches Anwendungsbeispiel für eine Normalverteilung ist der Intelligenzquotient. Dessen Skala ist so definiert, dass sie einer Normalverteilung $NV(\mu=100,\sigma = 15)$ entspricht. Betrachten wir Person A mit einem IQ von 130. Wie viel Prozent der IQ-Werte liegen unter einem IQ von 130? Um diese Frage zu beantworten müssen wir den Wert z-Standardisieren entsprechend der folgenden Formel:
$$z=\frac{x-\mu}{\sigma}$$ Also setzen wir ein und erhalten $\frac{130-100}{15} = 2$: 
```{r, warning=F,message=F,fig.width=8,fig.height=3.5, fig.align="center", echo = F}
data2 <- data.frame(iq = seq(50,150,1)) # dataframe mit Zahlenfolge
data2$iq_density <- dnorm(x=data2$iq,mean = 100 ,sd =  15) # Dichtefunktion 
##d4ba55


nv_iq <- ggplot(data = data2, aes(x=iq, y = iq_density )) + 
  geom_ribbon(data=filter(data2,iq <= 130), aes(ymin = 0, ymax = iq_density), fill = "#57B5ED" , alpha = .5 )+
  geom_line(color = "#273253", size = .75, linetype = 1)  +   
  theme_minimal() + labs(y = "Häufigkeitsdichte", x = "Intelligenzquotient", title = "IQ") +
  theme(aspect.ratio = .5,
        panel.grid.major = element_line(size = .1),panel.grid.minor = element_blank()) 
dnorm1 <- ggplot(data = data1, aes(x=z, y = nv_density )) + 
  geom_ribbon(data=filter(data1,z <= 2), aes(ymin = 0, ymax = nv_density), fill = "#ff8c69" , alpha = .5 )+
  geom_line(color = "#35274A", size = .75)  +   
  scale_y_continuous(breaks = seq(0,.4,.2)) +
  theme_minimal() + labs(y = "Häufigkeitsdichte", x = "z-Wert", title = "Standard-NV") +
  theme(aspect.ratio = .5,
        panel.grid.major = element_line(size = .1),panel.grid.minor = element_blank()) 

nv_iq + dnorm1
```

Diesen z-Wert von 2 können wir nun in die Verteilungsfunktion einsetzen:
```{stata z2}
display normal(2)
```

`r round(pnorm(q=2)*100,3)`% aller IQ-Werte sind also kleiner als 130. Daraus ergibt sich auch: $100\%-`r round(pnorm(q=2)*100,3)`\% =$ `r round(100-pnorm(q=2)*100,3)`% aller IQ-Werte sind *größer* als 130.

Wir können auch umgekehrt fragen, welcher IQ-Wert nötig ist, um zu den höchsten 1% zu gehören. Dazu formen wir die Standardisierungsformel zu $\mu+z\times\sigma$ um. $\mu$=100,$\sigma$ = 15 ergeben sich aus der IQ-Definition. Den z-Wert für das 99%-Quantil bekommen wir mit `invnormal(.99)`:
```{stata top1}
display invnormal(.99)
```
```{stata topbound}
display 100 + 2.3263479*15 
```

Um beim IQ zu den Top 1% zu gehören, ist ein IQ von mindestens `r round(qnorm(p = 0.99, mean = 100, sd = 15),3)` nötig. 


```{r, warning=F,message=F,fig.width=8,fig.height=3.5, fig.align="center", echo = F}
data2 <- data.frame(iq = seq(50,150,1)) # dataframe mit Zahlenfolge
data2$iq_density <- dnorm(x=data2$iq,mean = 100 ,sd =  15) # Dichtefunktion 
##d4ba55


nv_iq2 <- ggplot(data = data2, aes(x=iq, y = iq_density )) + 
  geom_ribbon(data=filter(data2,iq >= qnorm(p = 0.99, mean = 100, sd = 15)), aes(ymin = 0, ymax = iq_density),fill= "#57B5ED" , alpha = .5 ) +
  geom_line(color = "#273253", size = .75, linetype = 1)  +   
  geom_text(data=filter(data2,iq == 135), aes(x = iq, y = .0075, label = iq)) +
  theme_minimal() + labs(y = "Häufigkeitsdichte", x = "Intelligenzquotient", title = "IQ") +
  theme(aspect.ratio = .5,
        panel.grid.major = element_line(size = .1),panel.grid.minor = element_blank()) 

dnorm2 <- ggplot(data = data1, aes(x=z, y = nv.var )) + 
  geom_ribbon(data=filter(data1,z >=qnorm(p = 0.99)), aes(ymin = 0, ymax = nv.var),fill = "#ff8c69" , alpha = .5 )+
  geom_line(color = "#35274A", size = .75)  +   
  geom_text(data=filter(data1,between(z,qnorm(p = 0.9899),qnorm(p = 0.9901) ) ), aes(x = z, y = .1, label = z)) +
  scale_y_continuous(breaks = seq(0,.4,.2)) +
  theme_minimal() + labs(y = "Häufigkeitsdichte", x = "z-Wert",title="Standard-NV") +
  theme(aspect.ratio = .5,
        panel.grid.major = element_line(size = .1),panel.grid.minor = element_blank()) 

nv_iq2 + dnorm2 
```



Welcher IQ ist höchstens unter den niedrigsten 1%?
```{stata bottom1}
display invnormal(.01) 
```
Dieser Wert ist negativ weil wir uns links vom Mittelwert befinden!

```{stata low1}
display 100 + -2.326348*15
```

```{r, warning=F,message=F,fig.width=8,fig.height=3.5, fig.align="center", echo = F}
nv_iq3 <- ggplot(data = data2, aes(x=iq, y = iq_density )) + 
  geom_ribbon(data=filter(data2,iq <= qnorm(p = 0.01, mean = 100, sd = 15)), aes(ymin = 0, ymax = iq_density),fill= "#57B5ED" , alpha = .5 ) +
  geom_line(color = "#273253", size = .75, linetype = 1)  +   
  geom_text(data=filter(data2,iq == 65), aes(x = iq, y = .0075, label = iq)) +
  theme_minimal() + labs(y = "Häufigkeitsdichte", x = "Intelligenzquotient", title = "IQ") +
  theme(aspect.ratio = .5,
        panel.grid.major = element_line(size = .1),panel.grid.minor = element_blank()) 

dnorm3 <- 
  ggplot(data = data1, aes(x=z, y = nv.var )) + 
  geom_ribbon(data=filter(data1,z <=qnorm(p = 0.01)), aes(ymin = 0, ymax = nv.var), fill = "#B1934AFF" , alpha = .5 )+
  geom_line(color = "#394165FF", size = .75)  +   
  geom_text(data=filter(data1,between(z,qnorm(p = 0.0099),qnorm(p = 0.0101) ) ), aes(x = z, y = .1, label = z)) +
  scale_y_continuous(breaks = seq(0,.4,.2)) +
  theme_minimal() + labs(y = "Häufigkeitsdichte", x = "z-Wert") +
  theme(aspect.ratio = .5,
        panel.grid.major = element_line(size = .1),panel.grid.minor = element_blank()) 

nv_iq3 + dnorm3 
```


### Student t-Verteilung

In der Praxis wird die Standardnormalverteilung aber nur selten genutzt, denn das oben gezeigte Vorgehen setzt voraus, dass die Standardabweichung in der Grundgesamtheit ($\sigma$) bekannt ist. Dies ist aber in der Regel nicht der Fall. Es ergeben sich zwei Möglichkeiten:  

+ Bei großen Stichproben kann die Standardabweichung der Stichprobe ($s$) als Schätzer für $\sigma$ verwendet werden (ab $n\geq30$)  

+ Verwendung der t-Verteilung, welche durch Freiheitsgrade die Stichprobengröße berücksichtigt

Die t-Verteilung ähnelt der Standardnormalverteilung, beide haben einen Mittelwert von $\mu = 0$. Streng genommen gibt es jedoch nicht eine t-Verteilung, sondern viele - diese unterscheiden sich durch die sogenannten Freiheitsgrade. Dieser wird mit `df` ("degrees of freedom") abgekürzt und entspricht der "Stichprobengröße minus 1": $n-1$. Im Vergleich zur Standardnormalverteilung hat die t-Verteilung "breitere" Ränder, die sich aber bei steigender Stichprobengröße (höheren `df`) der Standardnormalverteilung annähern:


```{r, out.width="100%", fig.align='center', echo = F}
 # data1 <- data.frame(z = seq(-4,4,.01)) # dataframe erstellen mit Zahlenfolge zwischen -4 & 4
data1$t.var <- dt(x=data1$z,df =  2) # Dichtefunktion der t-Verteilung mit df=2
data1$t.var10 <- dt(x=data1$z,df =  10) # Dichtefunktion der t-Verteilung mit df=10
data2 <- data1 %>% pivot_longer(cols = contains("var"),values_to = "nv",names_to = "Verteilung") %>% 
  mutate(Verteilung = case_when(grepl("nv",Verteilung)~ "Standard-NV",
                                grepl("t\\.var$",Verteilung)~ "Student-t mit df = 2",
                                grepl("t\\.var10$",Verteilung)~ "Student-t mit df = 10")) 

ggplot(data = data2, aes(x=z, color = Verteilung)) +   
  geom_line(aes(y= nv), size = .75) +
  scale_color_manual(values =c("#3B64A1","#3B414F","#B3875C"), name = "") +
  theme_minimal(base_size = 11) +
  labs(y = "Häufigkeitsdichte", x = "") +
  theme(legend.position = "top",
        panel.grid.major = element_line(size = .1),panel.grid.minor = element_blank()) +
  guides(colour = guide_legend(override.aes = list(shape = 15 ,size = 6) ,
                               label.position ="right" , ncol = 3,reverse = T) )
```
Wir können also einfach die t-Verteilung verwenden und die Stichprobengröße angeben - für große Stichproben wird sich das Ergebnis an die Standardnormalverteilung annähern. Bei kleineren Stichproben sind wir auf der sicheren Seite. Im Grundsatz können wir also für alle (annähernd) normalverteilen Merkmale die t-Verteilung verwenden.
 
Wie für die Standardnormalverteilung bekommen wir mit `ttail` angegeben, wieviel % der Fläche *rechts* eines t-Werts ("z-Wert der t-Verteilung") liegen bei einer bestimmten Zahl von `df`:
```{stata ttailx}
display ttail(2,1)
```
Für die Fläche links davon rechnen wir folglich `1-ttail`:
```{stata ttailx2}
display 1- ttail(2,1)
```
Bei einer Stichprobengröße von 3 (`df`$+1$) liegen `r round(pt(q=1,df =  2)*100,2)`% links von einem t-Wert = 1.

#### t-Standardisierung

Noch einmal zu unserem IQ-Beispiel: stellen wir uns vor, dass für den mittleren IQ ($\bar{IQ}$=100) und dessen Standardabweichung ($s$=15) auf einer Stichprobe von $n=15$ beruht. Wir würden uns wieder fragen, wie viel Prozent aller Personen in der Grundgesamtheit wohl einen IQ $\leq$ 130 haben. Zunächst verwenden wir wieder die Standardisierungsformel (diese ändert sich nicht im Vergleich zur Standard-NV):
$$t=\frac{x-\bar{x}}{s}$$ 
Also setzen wir ein und erhalten wie oben $\frac{130-100}{15} = 2$. 

Der Hauptunterschied zum Vorgehen bei der Standardnormalverteilung ist jetzt, dass wir anstelle von `invnormal` jetzt eben `1-ttail` mit der entsprechenden `df=n-1` verwenden:
```{stata ttail2}
dis 1-ttail(14,2)
```

Basierend auf einer Stichprobe von 15 Personen mit einem Mittelwert von 100 und einer Standardabweichung von 15 sind also `r round(pt(q = 2,df =  14)*100,3)`% aller IQ-Werte kleiner als 130. Daraus ergibt sich auch: $100\%-`r round(pt(q = 2,df =  14)*100,3)`\% =$ `r round(100-pt(q = 2,df =  14)*100,3)`% aller IQ-Werte sind *größer* als 130.

> Zum Vergleich: oben - auf Basis der Standard-NV - waren es `r round(pnorm(q=2)*100,3)`% 

Auch hier können wir uns natürlich umgekehrt fragen, wie hoch der IQ sein muss um zu den Top 1% zu gehören. Dazu suchen wir erst mit `invttail` den entsprechenden t-Wert und setzen dann wieder in die umgeformte Formel $\bar{x}+t\times s$ ein:
```{stata invtt1}
dis invttail(14,.99)
```

Da wir die obere/rechte Grenze suchen, verwenden wir +2.6244941:
```{stata invtt2}
display 100 + 2.6244941* 15
```

Basierend auf einer Stichprobe von 15 Personen mit einem Mittelwert von 100 und einer Standardabweichung von 15 ist also ein IQ von `r round(100 +qt(p=.99,df=14)*15,3)` nötig, um zu den Top 1% zu gehören.

> Zum Vergleich: oben - auf Basis der Standard-NV - waren es `r round(qnorm(p = 0.99, mean = 100, sd = 15),3)`.

```{r,out.width="100%", fig.align='center', echo = F}
data1$t.var <- dt(x=data1$z,df =  2) # Dichtefunktion der t-Verteilung mit df=2
data1$t.var14 <- dt(x=data1$z,df =  14) # Dichtefunktion der t-Verteilung mit df=14


ggplot(data = data1, aes(x=z, y = t.var14 )) + 
  geom_ribbon(data=filter(data1,z >= qt(p=.99,df=14)), aes(ymin = 0, ymax = t.var14), fill = "#B1934AFF" , alpha = .5 )+
  geom_line(color = "#394165FF", size = .75)  +   
  geom_text(data=filter(data1,between(z,qt(p=.9899,df=14),qt(p=.9901,df=14) ) ), aes(x = z, y = .05, label = z)) +
  scale_y_continuous(breaks = seq(0,.4,.2)) +
  theme_minimal() + labs(y = "Häufigkeitsdichte", x = "t-Wert", title = "t-Verteilung mit df = 14") +
  theme(aspect.ratio = .5,
        panel.grid.major = element_line(size = .1),panel.grid.minor = element_blank()) 
```



